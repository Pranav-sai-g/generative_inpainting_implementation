# =========================== Basic Settings ===========================
# machine info
num_gpus_per_job: 1  # number of gpus each job need
num_cpus_per_job: 4  # number of gpus each job need
num_hosts_per_job: 1
memory_per_job: 32  # number of gpus each job need
gpu_type: 'nvidia-tesla-p100'

# parameters
name: places2_gated_conv_v100  # any name
model_restore: ''  # logs/places2_gated_conv
dataset: 'celebahq'  # 'tmnist', 'dtd', 'places2', 'celeba', 'imagenet', 'cityscapes'
random_crop: False  # Set to false when dataset is 'celebahq', meaning only resize the images to img_shapes, instead of crop img_shapes from a larger raw image. This is useful when you train on images with different resolutions like places2. In these cases, please set random_crop to true.
val: False  # true if you want to view validation results in tensorboard
log_dir: logs/full_model_celeba_hq_256

gan: 'sngan'
gan_loss_alpha: 1
gan_with_mask: True
discounted_mask: True
random_seed: False
padding: 'SAME'

# training
train_spe: 4000
max_iters: 100000000
viz_max_out: 10
val_psteps: 2000

# data
data_flist:
  # https://github.com/jiahuiyu/progressive_growing_of_gans_tf
  celebahq: [
    'data/celeba_hq/train_shuffled.flist',
    'data/celeba_hq/validation_static_view.flist'
  ]
  # http://mmlab.ie.cuhk.edu.hk/projects/celeba.html, please to use random_crop: True
  celeba: [
    'data/celeba/train_shuffled.flist',
    'data/celeba/validation_static_view.flist'
  ]
  # http://places2.csail.mit.edu/, please download the high-resolution dataset and use random_crop: True
  places2: [
    'data/places2/train_shuffled.flist',
    'data/places2/validation_static_view.flist'
  ]
  # http://www.image-net.org/, please use random_crop: True
  imagenet: [
    'data/imagenet/train_shuffled.flist',
    'data/imagenet/validation_static_view.flist',
  ]

static_view_size: 30
img_shapes: [256, 256, 3]
height: 128
width: 128
max_delta_height: 32
max_delta_width: 32
batch_size: 16
vertical_margin: 0
horizontal_margin: 0

# loss
ae_loss: True
l1_loss: True
l1_loss_alpha: 1.

# to tune
guided: False
edge_threshold: 0.6








import argparse
import os
from random import shuffle

parser = argparse.ArgumentParser()
parser.add_argument('--folder_path', default='./training_data', type=str,
                    help='The folder path')
parser.add_argument('--train_filename', default='./data_flist/train_shuffled.flist', type=str,
                    help='The train filename.')
parser.add_argument('--validation_filename', default='./data_flist/validation_shuffled.flist', type=str,
                    help='The validation filename.')
parser.add_argument('--is_shuffled', default='1', type=int,
                    help='Needed to be shuffled')

if __name__ == "__main__":

    args = parser.parse_args()

    # get the list of directories and separate them into 2 types: training and validation
    training_dirs = os.listdir(args.folder_path + "/training")
    validation_dirs = os.listdir(args.folder_path + "/validation")

    # make 2 lists to save file paths
    training_file_names = []
    validation_file_names = []

    # append all files into 2 lists
    for training_dir in training_dirs:
        # append each file into the list file names
        training_folder = os.listdir(args.folder_path + "/training" + "/" + training_dir)
        for training_item in training_folder:
            # modify to full path -> directory
            training_item = args.folder_path + "/training" + "/" + training_dir + "/" + training_item
            training_file_names.append(training_item)

    # append all files into 2 lists
    for validation_dir in validation_dirs:
        # append each file into the list file names
        validation_folder = os.listdir(args.folder_path + "/validation" + "/" + validation_dir)
        for validation_item in validation_folder:
            # modify to full path -> directory
            validation_item = args.folder_path + "/validation" + "/" + validation_dir + "/" + validation_item
            validation_file_names.append(validation_item)

    # print all file paths
    for i in training_file_names:
        print(i)
    for i in validation_file_names:
        print(i)

    # shuffle file names if set
    if args.is_shuffled == 1:
        shuffle(training_file_names)
        shuffle(validation_file_names)

    # make output file if not existed
    if not os.path.exists(args.train_filename):
        os.mknod(args.train_filename)

    if not os.path.exists(args.validation_filename):
        os.mknod(args.validation_filename)

    # write to file
    fo = open(args.train_filename, "w")
    fo.write("\n".join(training_file_names))
    fo.close()

    fo = open(args.validation_filename, "w")
    fo.write("\n".join(validation_file_names))
    fo.close()

    # print process
    print("Written file is: ", args.train_filename, ", is_shuffle: ", args.is_shuffled)
